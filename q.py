#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import re, os, sys, time, logging, subprocess, threading
import numpy as np, sentencepiece as spm, soundfile as sf
from typing import Optional, Tuple, Dict, Any, List, Union
import signal, audioop, atexit 
from queue import Queue
from pathlib import Path
from enum import Enum
from onnxruntime import (GraphOptimizationLevel, InferenceSession,
                         SessionOptions, get_available_providers, get_device)
import pyaudio, select, yaml, math, psutil, gc, uuid, cn2an, kaldi_native_fbank as knf, onnxruntime as ort
from rknnlite.api.rknn_lite import RKNNLite

# å†…å­˜ç›‘æ§å·¥å…·ç±»
class MemoryMonitor:
    def __init__(self):
        self.process = psutil.Process()
        self.logger = logging.getLogger("MemoryMonitor")
        self.baseline_memory = self.get_memory_info()
        vm = psutil.virtual_memory()
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"ğŸ”§ RK3588 æ¿å­å†…å­˜é…ç½®:")
        self.logger.info(f"  æ€»å†…å­˜: {vm.total / 1024 / 1024:.2f} MB ({vm.total / 1024 / 1024 / 1024:.2f} GB)")
        self.logger.info(f"  åˆå§‹å¯ç”¨: {vm.available / 1024 / 1024:.2f} MB")
        self.logger.info(f"  åˆå§‹ä½¿ç”¨ç‡: {vm.percent:.2f}%")
        self.logger.info(f"{'='*60}\n")
        
    def get_memory_info(self) -> Dict[str, float]:
        mem_info = self.process.memory_info()
        virtual_mem = psutil.virtual_memory()
        
        return {
            'process_rss': mem_info.rss / 1024 / 1024,
            'process_vms': mem_info.vms / 1024 / 1024,
            'process_percent': self.process.memory_percent(),
            'system_total': virtual_mem.total / 1024 / 1024,
            'system_available': virtual_mem.available / 1024 / 1024,
            'system_used': virtual_mem.used / 1024 / 1024,
            'system_percent': virtual_mem.percent,
            'system_free': virtual_mem.free / 1024 / 1024,
            'system_buffers': getattr(virtual_mem, 'buffers', 0) / 1024 / 1024,
            'system_cached': getattr(virtual_mem, 'cached', 0) / 1024 / 1024,
        }
    
    def log_memory(self, stage: str, details: str = ""):
        mem = self.get_memory_info()
        delta_process = mem['process_rss'] - self.baseline_memory['process_rss']
        delta_system = mem['system_used'] - self.baseline_memory['system_used']
        
        log_msg = (
            f"\n{'='*70}\n"
            f"ğŸ“Š [{stage}] RK3588 æ¿å­å†…å­˜çŠ¶æ€ {details}\n"
            f"{'='*70}\n"
            f"ğŸ–¥ï¸  æ¿å­ç³»ç»Ÿå†…å­˜:\n"
            f"  â”œâ”€ æ€»å†…å­˜: {mem['system_total']:.2f} MB\n"
            f"  â”œâ”€ å·²ä½¿ç”¨: {mem['system_used']:.2f} MB ({mem['system_percent']:.2f}%)\n"
            f"  â”œâ”€ å¯ç”¨å†…å­˜: {mem['system_available']:.2f} MB\n"
            f"  â””â”€ ç³»ç»Ÿå†…å­˜å˜åŒ–: {delta_system:+.2f} MB\n"
            f"\n"
            f"ğŸ“± æœ¬è¿›ç¨‹å†…å­˜:\n"
            f"  â”œâ”€ ç‰©ç†å†…å­˜: {mem['process_rss']:.2f} MB\n"
            f"  â”œâ”€ å æ¿å­æ€»å†…å­˜: {mem['process_percent']:.2f}%\n"
            f"  â””â”€ è¿›ç¨‹å†…å­˜å˜åŒ–: {delta_process:+.2f} MB\n"
            f"{'='*70}"
        )
        self.logger.info(log_msg)
        return mem
    
    def get_memory_delta(self, start_mem: Dict[str, float]) -> Dict[str, float]:
        current_mem = self.get_memory_info()
        return {
            'process_rss_delta': current_mem['process_rss'] - start_mem['process_rss'],
            'system_used_delta': current_mem['system_used'] - start_mem['system_used'],
            'system_available_delta': current_mem['system_available'] - start_mem['system_available'],
            'system_percent_delta': current_mem['system_percent'] - start_mem['system_percent'],
        }
    
    def format_delta(self, delta: Dict[str, float]) -> str:
        return (
            f"[æ¿å­] å·²ç”¨: {delta['system_used_delta']:+.2f} MB, "
            f"ä½¿ç”¨ç‡: {delta['system_percent_delta']:+.2f}% | "
            f"[è¿›ç¨‹] RSS: {delta['process_rss_delta']:+.2f} MB"
        )

memory_monitor = MemoryMonitor()

# --- å…¨å±€é…ç½® ---
ASR_DIR = "/home/orangepi/rknn-asr/runtime/RK3588/Linux/librknn_api/include"
LLM_SCRIPT_PATH = "/root/voice_assistant/run_llm.sh"
LLM_DIR = os.path.dirname(LLM_SCRIPT_PATH)
TTS_DIR = "/home/orangepi/rknn-tts/MeloTTS-RKNN2"
WORKDIR = os.path.join(os.path.expanduser("~"), "voice_assistant")
os.makedirs(WORKDIR, exist_ok=True)

sys.path.append(ASR_DIR)
sys.path.append(TTS_DIR)
from sensevoice_rknn import *
from melotts_rknn import *

ASR_RKNN_PATH = os.path.join(ASR_DIR, "sense-voice-encoder.rknn") ##
ASR_EMBED_PATH = os.path.join(ASR_DIR, "embedding.npy")
ASR_BPE_PATH = os.path.join(ASR_DIR, "chn_jpn_yue_eng_ko_spectok.bpe.model")
ASR_VAD_ONNX_PATH = os.path.join(ASR_DIR, "fsmnvad-offline.onnx")
ASR_VAD_CONFIG_YAML = os.path.join(ASR_DIR, "fsmn-config.yaml")
ASR_MVN_PATH = os.path.join(ASR_DIR, "am.mvn")

TTS_ENCODER_PATH = os.path.join(TTS_DIR, "encoder.onnx")
TTS_DECODER_PATH = os.path.join(TTS_DIR, "decoder.rknn") ##
TTS_LEXICON_PATH = os.path.join(TTS_DIR, "lexicon.txt")
TTS_TOKEN_PATH = os.path.join(TTS_DIR, "tokens.txt")
TTS_G_BIN_PATH = os.path.join(TTS_DIR, "g.bin")

RATE = 16000
PLAY_DEVICE = "hw:0,0"
TARGET_PLAY_SR = 16000
TARGET_PLAY_CH = 2

audio_queue = Queue()
play_queue = Queue()

def playback_worker():
    logger = logging.getLogger("PlaybackWorker")
    while True:
        wav_path = play_queue.get()  # é˜»å¡ç­‰å¾…
        if wav_path is None:  # ç»“æŸä¿¡å·ï¼ˆç¨‹åºé€€å‡ºæ—¶å¯å‘ï¼‰
            break
        success = play_audio_file(wav_path, 0, PLAY_DEVICE)
        os.remove(wav_path)

class RecorderState(Enum):
    STOPPED = 0
    LISTENING = 1
    RECORDING = 2

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s [%(name)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
# --- ASR æœåŠ¡ ---
class AsrService:
    def __init__(self, mvn_path, embed_path, rknn_path, bpe_path, asr_dir):
        self.logger = logging.getLogger("AsrService")
        self.logger.info("åŠ è½½ ASR æ¨¡å‹...")
        start_time = time.time() ###
        self.front = WavFrontend(cmvn_file=mvn_path) 
        self.vad = FSMNVad(asr_dir)
        self.model = SenseVoiceInferenceSession(
            embed_path, rknn_path, bpe_path, device_id=-1, intra_op_num_threads=4
        )
        self.languages = {"auto": 0, "zh": 3, "en": 4, "yue": 7, "ja": 11, "ko": 12, "nospeech": 13}
        
        self.logger.info(f"ASRæ¨¡å‹åŠ è½½å®Œæ¯•ï¼Œè€—æ—¶ {time.time() - start_time:.2f} ç§’ã€‚")

    def transcribe(self, waveform_16k_f32, language="zh", use_itn=True) -> Tuple[str, float]:
        self.logger.info("å¼€å§‹ ASR æ¨ç†...")
        start_time = time.time()
        
        segments = self.vad.segments_offline(waveform_16k_f32) 
        
        if not segments:
            self.logger.warning("VAD æœªæ£€æµ‹åˆ°è¯­éŸ³ç‰‡æ®µã€‚")
            return "", 0.0
            
        self.logger.info(f"VAD æ£€æµ‹åˆ° {len(segments)} ä¸ªç‰‡æ®µã€‚")
        full_text = []

        for i, part in enumerate(segments):
            start_ms, end_ms = part[0], part[1]
            start_frame = int(start_ms * 16) 
            end_frame = int(end_ms * 16)
            segment_audio = waveform_16k_f32[start_frame:end_frame]
            
            if len(segment_audio) < 160: 
                continue 

            audio_feats = self.front.get_features(segment_audio)
            asr_result = self.model(
                audio_feats[None, ...], 
                language=self.languages.get(language, 0), 
                use_itn=use_itn
            )
            
            self.logger.info(f"[ç‰‡æ®µ {i}] [{start_ms/1000:.2f}s - {end_ms/1000:.2f}s] {asr_result}")
            full_text.append(asr_result)
        
        final_text = "".join(full_text)
        cleaned_text = re.sub(r'<\|[^>]*\|>', '', final_text)
        cleaned_text = cleaned_text.strip(' \n\r\t,ã€‚!?:;"\'ã€‚')
        
        if cleaned_text:
            cleaned_text += "ï¼Œå›ç­”ç®€çŸ­ä¸€äº›ï¼Œä¿æŒ50å­—ä»¥å†…ï¼"
            final_text = cleaned_text
            
        elapsed = time.time() - start_time
        return final_text, elapsed

    def close(self):
        self.model.release()

# --- LLM æœåŠ¡ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰ ---
ANSI_RE = re.compile(r'\x1b\[[0-9;]*[A-Za-z]')
class LlmService:
    def __init__(self, script_path: str, cwd_dir: Optional[str] = None, idle_timeout: float = 1.2, init_timeout: float = 120.0):
        self.logger = logging.getLogger("LlmService")
        self.script_path = script_path
        self.idle_timeout = float(idle_timeout)
        self.init_timeout = float(init_timeout)
        self._proc: Optional[subprocess.Popen] = None
        self._lock = threading.Lock()
        self._stdout_fd: Optional[int] = None
        self._start_and_wait_ready()

    def _start_and_wait_ready(self):
        self.logger.info(f"å¯åŠ¨ LLM å®ˆæŠ¤è¿›ç¨‹: {self.script_path}")
        
        self._proc = subprocess.Popen(
            [self.script_path],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            bufsize=0,
            close_fds=True
        )

        self._stdout_fd = self._proc.stdout.fileno()

        ready_buf = ""
        start = time.time()
        while True:
            elapsed = time.time() - start
            remaining = max(0.1, self.init_timeout - elapsed)
            rlist, _, _ = select.select([self._stdout_fd], [], [], remaining)
            if rlist:
                chunk = os.read(self._stdout_fd, 4096)
                if not chunk:
                    break
                s = chunk.decode("utf-8", errors="ignore")
                ready_buf += s
                if "rkllm init success" in ready_buf:
                    self.logger.info("LLM å·²åˆå§‹åŒ–å®Œæˆã€‚")
                    return
            else:
                if time.time() - start >= self.init_timeout:
                    self.logger.error("ç­‰å¾… 'rkllm init success' è¶…æ—¶ã€‚")
                    raise TimeoutError("LLM init timeout")

    def chat_stream(self, prompt_text: str, sentence_callback):
        if not prompt_text:
            return "", 0.0, 0.0

        with self._lock:
            start_time = time.time()
            first_sentence_time = None  # é¦–å¥ç”Ÿæˆæ—¶é—´
            
            self._proc.stdin.write((prompt_text + "\n").encode("utf-8"))
            self._proc.stdin.flush()

            collected = ""
            fd = self._stdout_fd
            
            # å¥å­åˆ†éš”ç¬¦ï¼ˆä¸­è‹±æ–‡æ ‡ç‚¹ï¼‰
            sentence_delimiters = ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', 'ï¼Œ', 'ï¼›']
            buffer = ""  # å½“å‰ç§¯ç´¯çš„æ–‡æœ¬
            sentence_count = 0

            while True:
                timeout = self.idle_timeout
                rlist, _, _ = select.select([fd], [], [], timeout)

                if rlist:
                    chunk = os.read(fd, 4096)
                    if not chunk:
                        break
                    s = chunk.decode("utf-8", errors="ignore")
                    collected += s
                    
                    # æ¸…ç† ANSI å’Œè¿‡æ»¤æ—¥å¿—è¡Œ
                    s_clean = ANSI_RE.sub("", s)
                    for line in s_clean.split('\n'):
                        line = line.rstrip()
                        if not line:
                            continue
                        # è·³è¿‡æ—¥å¿—å’Œæç¤ºç¬¦
                        if line.startswith("I rkllm:") or line.startswith("rkllm init") or \
                           line.startswith("Input:") or line.startswith("user:") or \
                           "time_used=" in line or line == prompt_text:
                            continue
                        
                        # æå– robot: åçš„å†…å®¹
                        if line.lower().startswith("robot:"):
                            line = line[len("robot:"):].strip()
                        
                        buffer += line
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´å¥å­
                    for delimiter in sentence_delimiters:
                        if delimiter in buffer:
                            # æŒ‰åˆ†éš”ç¬¦åˆ†å‰²
                            parts = buffer.split(delimiter)
                            # å¤„ç†é™¤æœ€åä¸€ä¸ªä¹‹å¤–çš„æ‰€æœ‰éƒ¨åˆ†ï¼ˆå®ƒä»¬æ˜¯å®Œæ•´å¥å­ï¼‰
                            for i in range(len(parts) - 1):
                                sentence = parts[i].strip() + delimiter
                                if sentence.strip(delimiter).strip():  # ç¡®ä¿ä¸æ˜¯ç©ºå¥å­
                                    sentence_count += 1
                                    current_time = time.time()
                                    
                                    # è®¡ç®—é¦–å¥æ—¶é—´ï¼ˆä»LLMå¼€å§‹åˆ°ç¬¬ä¸€ä¸ªæ ‡ç‚¹ç¬¦å·ï¼‰
                                    is_first = (sentence_count == 1)
                                    if is_first:
                                        first_sentence_time = current_time - start_time
                                        self.logger.info(f"âš¡ LLM é¦–å¥ç”Ÿæˆæ—¶é—´: {first_sentence_time:.2f}s")
                                    
                                    # è®¡ç®—å¥å­é—´éš”æ—¶é—´
                                    sentence_time = current_time - start_time
                                    
                                    self.logger.info(f"ğŸ“ LLM å¥å­ [{sentence_count}] (ç´¯è®¡ {sentence_time:.2f}s): {sentence}")
                                    # è°ƒç”¨å›è°ƒå‡½æ•°
                                    sentence_callback(sentence, sentence_time, is_first)
                            
                            # ä¿ç•™æœ€åä¸€ä¸ªéƒ¨åˆ†ï¼ˆå¯èƒ½æ˜¯æœªå®Œæˆçš„å¥å­ï¼‰
                            buffer = parts[-1]
                            break
                    
                    continue
                else:
                    break
            
            # å¤„ç†å‰©ä½™çš„æ–‡æœ¬
            if buffer:
                sentence_count += 1
                current_time = time.time()
                sentence_time = current_time - start_time
                is_first = (sentence_count == 1)
                if is_first:
                    first_sentence_time = current_time - start_time
                    self.logger.info(f"âš¡ LLM é¦–å¥ç”Ÿæˆæ—¶é—´: {first_sentence_time:.2f}s")
                self.logger.info(f"ğŸ“ LLM æœ€åç‰‡æ®µ [{sentence_count}] (ç´¯è®¡ {sentence_time:.2f}s): {buffer}")
                sentence_callback(buffer.strip(), sentence_time, is_first)

            # è§£æå®Œæ•´è¾“å‡º
            raw_output = ANSI_RE.sub("", collected)
            lines = [ln.strip() for ln in raw_output.splitlines() if ln.strip()]

            # æå–æ€»è€—æ—¶
            llm_report_sec = 0.0
            for ln in reversed(lines):
                if "time_used=" in ln:
                    m = re.search(r"time_used\s*=\s*(\d+)\s*ms", ln)
                    if m:
                        llm_report_sec = float(m.group(1)) / 1000.0
                    break

            # æå–å®Œæ•´å›ç­”
            robot_idx = None
            for i, ln in enumerate(lines):
                if ln.lower().startswith("robot:"):
                    robot_idx = i

            answer = ""
            if robot_idx is not None:
                captured = []
                for ln in lines[robot_idx:]:
                    if "time_used=" in ln:
                        break
                    if ln.lower().startswith("robot:"):
                        captured.append(ln[len("robot:"):].strip())
                    else:
                        captured.append(ln)
                answer = " ".join([c for c in captured if c]).strip()
            else:
                filtered = []
                for ln in lines:
                    if ln.startswith("I rkllm:") or ln.startswith("rkllm init") or ln.startswith("Input:"):
                        continue
                    if "time_used=" in ln:
                        continue
                    if ln.lower().startswith("user:"):
                        continue
                    if ln == prompt_text or ln.startswith(prompt_text):
                        continue
                    filtered.append(ln)
                answer = " ".join(filtered).strip()

            if prompt_text and answer.lower().startswith(prompt_text.lower()):
                answer = answer[len(prompt_text):].strip()
            answer = re.sub(r'(?i)^user:\s*', '', answer).strip()
            answer = re.sub(r'\s+', ' ', answer).strip()

            elapsed = time.time() - start_time
            report_time = llm_report_sec if llm_report_sec > 0 else elapsed

            self.logger.info(f"ğŸ’¬ LLM å®Œæ•´å›ç­”: {answer!r}ï¼Œæ€»è€—æ—¶: {report_time:.3f}s")
            return answer, report_time, first_sentence_time if first_sentence_time else 0.0

    def close(self):
        if self._proc and self._proc.poll() is None:
            self._proc.send_signal(signal.SIGINT)
            self._proc.wait(timeout=3)
        self.logger.info("LLM å®ˆæŠ¤è¿›ç¨‹å·²å…³é—­ã€‚")

# --- TTS æœåŠ¡ ---
class TtsService:
    def __init__(self, encoder_path, decoder_path, lexicon_path, token_path, g_bin_path, sample_rate=44100, speed=1.0):
        self.logger = logging.getLogger("TtsService")
        self.sample_rate = sample_rate
        self.speed = speed
        self.dec_len = 65536 // 512  # 128
        self.logger.info("æ­£åœ¨åŠ è½½ TTS æ¨¡å‹...")
        start_time = time.time() ###

        self.lexicon = Lexicon(lexicon_path, token_path)
        sess_opt = SessionOptions()
        sess_opt.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL
        self.sess_enc = InferenceSession(encoder_path, sess_opt, providers=["CPUExecutionProvider"])
        self.decoder = RKNNLite()
        ret = self.decoder.load_rknn(decoder_path)
        if ret != 0:
            raise RuntimeError("Load decoder.rknn failed")
        self.decoder.init_runtime(core_mask=RKNNLite.NPU_CORE_0_1_2)
        self.g = np.fromfile(g_bin_path, dtype=np.float32).reshape(1, 256, 1)
        self.logger.info(f"TTS æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶ {time.time() - start_time:.2f}s")

    def synthesize_sentence(self, text: str, output_path: str) -> Tuple[bool, float, float, float]:
        start_time = time.time()
        enc_time = dec_time = 0.0

        text = text.strip()
        if not text:
            return False, 0, 0, 0

        # ç›´æ¥ä½¿ç”¨åŸå¥ï¼ˆä¸å†åˆ‡åˆ†ï¼‰ï¼Œå› ä¸ºå¥å­å¾ˆçŸ­
        audio_segments = []

        phone_str, yinjie_num, phones, tones = self.lexicon.convert(text)

        # åŠ  blank
        phone_str = intersperse(phone_str, 0)
        phones_np = np.array(intersperse(phones, 0), dtype=np.int32)
        tones_np = np.array(intersperse(tones, 0), dtype=np.int32)
        yinjie_num = np.array(yinjie_num, dtype=np.int32) * 2
        if yinjie_num.size > 0:
            yinjie_num[0] += 1

        pron_slices = generate_pronounce_slice(yinjie_num)
        phone_len = phones_np.shape[0]
        language = np.array([3] * phone_len, dtype=np.int32)

        # Encoder
        enc_start = time.time()
        z_p, pronoun_lens, audio_len_scalar = self.sess_enc.run(None, {
            'phone': phones_np,
            'g': self.g,
            'tone': tones_np,
            'language': language,
            'noise_scale': np.array([0.0], dtype=np.float32),
            'length_scale': np.array([1.0 / self.speed], dtype=np.float32),
            'noise_scale_w': np.array([0.0], dtype=np.float32),
            'sdp_ratio': np.array([0.0], dtype=np.float32),
        })
        enc_time += time.time() - enc_start

        audio_len = int(audio_len_scalar)
        pronoun_lens = np.array(pronoun_lens).flatten()
        pron_num = generate_word_pron_num(pronoun_lens, pron_slices)

        # z_p padding åˆ° decoder èƒ½æ•´é™¤çš„é•¿åº¦
        actual_size = z_p.shape[-1]
        need_pad = self.dec_len * ((actual_size + self.dec_len - 1) // self.dec_len) - actual_size
        if need_pad > 0:
            z_p = np.pad(z_p, ((0,0),(0,0),(0, need_pad)), 'constant')

        # åˆ†ç‰‡è§£ç ï¼ˆå¸¦ overlap + stripï¼‰
        pron_num_slices, zp_slices, strip_flags, _, is_long_list = generate_decode_slices(pron_num, self.dec_len)

        sub_audio_list = []
        for i in range(len(pron_num_slices)):
            p_start, p_end = pron_num_slices[i]
            z_start, z_end = zp_slices[i]
            strip_head, strip_tail = strip_flags[i]

            if is_long_list[i]:
                # è¶…é•¿è¯å•ç‹¬å¤„ç†
                sub_audio_list.extend(decode_long_word(self.decoder, z_p[..., z_start:z_end], self.g, self.dec_len))
            else:
                zp_slice = z_p[..., z_start:z_end]
                if zp_slice.shape[-1] < self.dec_len:
                    zp_slice = np.pad(zp_slice, ((0,0),(0,0),(0, self.dec_len - zp_slice.shape[-1])), 'constant')

                dec_start = time.time()
                audio_raw = self.decoder.inference(inputs=[zp_slice, self.g])[0].flatten()
                dec_time += time.time() - dec_start

                audio_raw = audio_raw[:512 * (z_end - z_start)]

                if strip_head and p_start > 0:
                    audio_raw = audio_raw[512 * pron_num[p_start]:]
                if strip_tail and p_end < len(pron_num):
                    audio_raw = audio_raw[:-512 * pron_num[p_end - 1]]

                sub_audio_list.append(audio_raw)

        merged_audio = merge_sub_audio(sub_audio_list, pad_size=0, audio_len=audio_len)
        audio_segments.append(merged_audio)

        final_audio = audio_numpy_concat(audio_segments, sr=self.sample_rate, speed=self.speed)
        sf.write(output_path, final_audio, self.sample_rate)
        total_time = time.time() - start_time
        return True, total_time, enc_time, dec_time

    def close(self):
        self.decoder.release()

# --- å½•éŸ³å™¨ ---
class AudioRecorder:
    logger = logging.getLogger("AudioRecorder")
    p = None
    stream = None
    state = RecorderState.STOPPED
    CHANNELS = 1
    FORMAT = pyaudio.paInt16
    CHUNK = 1024
    RMS_THRESHOLD = 300
    SILENCE_TIMEOUT_SEC = 1.8
    SILENCE_MAX_SEC = 5.0
    MAX_RECORD_SEC = 10.0

    @classmethod
    def start_stream(cls):
        if cls.p is None:
            cls.p = pyaudio.PyAudio()
        if cls.stream is None:
            cls.stream = cls.p.open(
                format=cls.FORMAT, channels=cls.CHANNELS, rate=RATE, input=True,
                frames_per_buffer=cls.CHUNK, start=False
            )
        atexit.register(cls.stop_stream)
        cls.logger.info("éº¦å…‹é£æµå·²åˆå§‹åŒ–ã€‚")

    @classmethod
    def stop_stream(cls):
        if cls.stream:
            cls.stream.stop_stream()
            cls.stream.close()
            cls.stream = None
        if cls.p:
            cls.p.terminate()
            cls.p = None
        cls.logger.info("éº¦å…‹é£æµå·²å…³é—­ã€‚")

    @classmethod
    def record_loop(cls):
        cls.start_stream()
        cls.stream.start_stream() 

        cls.state = RecorderState.LISTENING
        cls.logger.info("å½•éŸ³çº¿ç¨‹å¯åŠ¨ï¼Œè¿›å…¥ç›‘å¬æ¨¡å¼ã€‚")

        chunks_per_sec = RATE / cls.CHUNK
        silence_limit_chunks = int(chunks_per_sec * cls.SILENCE_TIMEOUT_SEC)
        max_record_chunks = int(chunks_per_sec * cls.MAX_RECORD_SEC)

        while cls.state != RecorderState.STOPPED:
            cls.logger.info("\n--- è¯·å¼€å§‹è¯´è¯ (æ­£åœ¨ç›‘å¬éº¦å…‹é£) ---")
            
            frames = []
            silent_chunks = 0
            is_recording = False
            LISTENING_timeout_start = time.time()

            while cls.state != RecorderState.STOPPED:
                if not is_recording and (time.time() - LISTENING_timeout_start > cls.SILENCE_MAX_SEC):
                    cls.logger.debug(f"ğŸ•“ {cls.SILENCE_MAX_SEC}ç§’æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œç»§ç»­ç›‘å¬...")
                    LISTENING_timeout_start = time.time()
                
                data = cls.stream.read(cls.CHUNK, exception_on_overflow=False)
                rms = audioop.rms(data, 2)

                if not is_recording:
                    if rms > cls.RMS_THRESHOLD:
                        cls.logger.info("ğŸ¯ æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å§‹å½•åˆ¶...")
                        is_recording = True
                        frames.append(data)
                        silent_chunks = 0
                
                elif is_recording:
                    frames.append(data)
                    if rms < cls.RMS_THRESHOLD:
                        silent_chunks += 1
                    else:
                        silent_chunks = 0
                    
                    current_chunks = len(frames)
                    
                    if silent_chunks > silence_limit_chunks:
                        cls.logger.info(f"ğŸ”‡ æ£€æµ‹åˆ° {cls.SILENCE_TIMEOUT_SEC}s é™éŸ³ï¼Œåœæ­¢å½•åˆ¶ã€‚")
                        break
                    
                    if current_chunks > max_record_chunks:
                        cls.logger.info(f"ğŸ¤ è¾¾åˆ°æœ€å¤§å½•åˆ¶æ—¶é•¿ ({cls.MAX_RECORD_SEC}ç§’)ï¼Œåœæ­¢å½•åˆ¶ã€‚")
                        break

            if is_recording and frames:
                audio_data_bytes = b"".join(frames)
                audio_data_int16 = np.frombuffer(audio_data_bytes,dtype = np.int16)
                audio_data_f32 = audio_data_int16.astype(np.float32) / 32768.0
                
                duration = len(audio_data_f32) / RATE
                if duration < 0.5:
                    cls.logger.info(f"å½•éŸ³å¤ªçŸ­ ({duration:.2f}s)ï¼Œå¿½ç•¥ã€‚")
                else:
                    cls.logger.info(f"å½•éŸ³å®Œæˆï¼Œæ€»æ—¶é•¿ {duration:.2f} ç§’ã€‚å°†æ•°æ®æ”¾å…¥é˜Ÿåˆ—ã€‚")
                    audio_queue.put(audio_data_f32)
            
        cls.stop_stream()

# --- éŸ³é¢‘æ’­æ”¾ï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ï¼‰ ---
def convert_to_target_format(src_file, dst_file, target_sr=TARGET_PLAY_SR, target_ch=TARGET_PLAY_CH):
    logger = logging.getLogger("AudioConverter")
    cmd = [
        "ffmpeg", "-y", "-i", src_file,
        "-ar", str(target_sr),
        "-ac", str(target_ch),
        "-acodec", "pcm_s16le",
        "-loglevel", "error",
        dst_file
    ]
    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        logger.warning(f"ffmpeg è½¬æ¢è­¦å‘Š: {result.stderr.decode()}")
    return result.returncode == 0

def play_audio_file(play_src_file, tts_gen_time, play_device=PLAY_DEVICE):
    logger = logging.getLogger("AudioPlayer")
    
    # ç›®æ ‡ä¸´æ—¶æ–‡ä»¶
    play_file = os.path.join("/dev/shm", f"tts_out_play_{int(time.time()*1000)}.wav")
    
    # è½¬æ¢éŸ³é¢‘æ ¼å¼ï¼ˆä¿è¯ 16k / 2ch / s16ï¼‰
    if not convert_to_target_format(play_src_file, play_file):
        logger.warning("âš ï¸ éŸ³é¢‘è½¬æ¢å¤±è´¥ï¼Œå°†ç›´æ¥æ’­æ”¾åŸæ–‡ä»¶")
        play_file = play_src_file

    # è¯»å–æ—¶é•¿ï¼Œä¸º aplay è®¾ç½® timeout
    duration = sf.info(play_file).duration
    start_play = time.time()
    played = False

    # åªä½¿ç”¨ä½ å·²ç»ç¡®è®¤èƒ½æ’­æ”¾çš„å‘½ä»¤
    cmd = ["aplay", "-D", play_device, play_file]
    logger.debug(f"æ’­æ”¾å‘½ä»¤: {' '.join(cmd)}")
    subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    logger.info(f"ğŸ”‰ TTS æ’­æ”¾è€—æ—¶: {time.time() - start_play:.2f}s")
    
    # æ’­æ”¾çŸ­å¤ä½éŸ³ï¼ˆå•å£°é“ï¼Œ16000Hzï¼ŒæŒç»­ 0.1~0.2sï¼‰
    #------- æ­¤RK3576æ¿å­ç‰¹æœ‰æ­¥éª¤ ----------
    reset_file = "/dev/shm/audio_reset.wav"
    subprocess.run(["aplay", "-D", play_device, reset_file],
                    stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=False)

    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    if os.path.exists(play_file) and play_file != play_src_file:
        os.remove(play_file)

    return played
    
# --- ä¸»å‡½æ•°ï¼ˆæ”¯æŒ LLM æµå¼ + TTS å®æ—¶åˆæˆï¼Œå¢å¼ºé”™è¯¯å¤„ç†ï¼‰ ---
def main():
    playback_thread = threading.Thread(target=playback_worker, daemon=True)
    playback_thread.start() 
    logger = logging.getLogger("MainPipeline")
    memory_monitor.log_memory("ç¨‹åºå¯åŠ¨")
    logger.info("=== æ™ºèƒ½åŠ©æ‰‹å¯åŠ¨ ===")
    
    # åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡
    logger.info("--- æ­£åœ¨åŠ è½½ ASR æœåŠ¡ ---")
    asr_service = AsrService(
        mvn_path=ASR_MVN_PATH, embed_path=ASR_EMBED_PATH, rknn_path=ASR_RKNN_PATH,
        bpe_path=ASR_BPE_PATH, asr_dir=ASR_DIR
    )
    
    logger.info("--- æ­£åœ¨åŠ è½½ LLM æœåŠ¡ ---")
    llm_service = LlmService(script_path="/root/voice_assistant/run_llm.sh", idle_timeout=5)#1.2

    logger.info("--- æ­£åœ¨åŠ è½½ TTS æœåŠ¡ ---")
    tts_service = TtsService(
        encoder_path=TTS_ENCODER_PATH, decoder_path=TTS_DECODER_PATH, lexicon_path=TTS_LEXICON_PATH,
        token_path=TTS_TOKEN_PATH, g_bin_path=TTS_G_BIN_PATH
    )
 
    # å¯åŠ¨å½•éŸ³çº¿ç¨‹
    recorder_thread = threading.Thread(target=AudioRecorder.record_loop, daemon=True)
    recorder_thread.start()
    
    # ä¸»å¾ªç¯
    while True:
        try:
            mem_pipeline_start = memory_monitor.get_memory_info()
            audio_data_f32 = audio_queue.get() 
            
            logger.info(f"\n--- ä»é˜Ÿåˆ—è·å–åˆ°æ–°çš„è¯­éŸ³ (æ—¶é•¿ {len(audio_data_f32) / RATE:.2f}s) ---")
            pipeline_start_time = time.time()
            memory_monitor.log_memory("æ–°ä¸€è½®æ¨ç†å¼€å§‹")
            
            # ASR
            user_text, asr_time = asr_service.transcribe(audio_data_f32, language="zh", use_itn=True)
            if not user_text:
                logger.warning("âš ï¸ ASR æœªè¿”å›æœ‰æ•ˆç»“æœï¼Œè·³è¿‡æœ¬è½®")
                continue
            logger.info(f"ğŸ“ å¬å†™ç»“æœ: {user_text}")
            
            # ç»Ÿè®¡ä¿¡æ¯
            tts_total_time = 0.0
            sentence_count = 0
            first_sentence_time = None
            
            # å®šä¹‰å¥å­å›è°ƒå‡½æ•°ï¼šæ¯ç”Ÿæˆä¸€ä¸ªå¥å­å°±è¿›è¡Œ TTS åˆæˆå¹¶ç«‹å³æ’­æ”¾
            def on_sentence_generated(sentence: str, sentence_time: float, is_first: bool):
                nonlocal tts_total_time, sentence_count, first_sentence_time

                sentence_clean = sentence.strip()
                for prefix in ["[ASRé”™è¯¯]", "[CMD]", "robot:", "assistant:"]:
                    if sentence_clean.lower().startswith(prefix.lower()):
                        sentence_clean = sentence_clean[len(prefix):].strip()

                if not sentence_clean:
                    return

                sentence_count += 1
                if is_first:
                    first_sentence_time = sentence_time

                #logger.info(f"ğŸµ å¼€å§‹åˆæˆç¬¬ {sentence_count} å¥: {sentence_clean}")
                wav_path = f"/dev/shm/tts_stream_{sentence_count}_{int(time.time()*1000)}.wav"
                
                # æ­£ç¡®è°ƒç”¨ï¼šä¸¤ä¸ªå‚æ•°
                success, tts_time, enc_time, dec_time = tts_service.synthesize_sentence(sentence_clean, wav_path)

                if success:
                    play_queue.put(wav_path)  # æ”¾å…¥æ’­æ”¾é˜Ÿåˆ—
                    logger.info(f"âœ… ç¬¬ {sentence_count} å¥åˆæˆå®Œæˆ ({tts_time:.3f}s)")
                    tts_total_time += tts_time
            
            # LLM æµå¼ç”Ÿæˆï¼ˆæ¯ä¸ªå¥å­ä¼šè§¦å‘ on_sentence_generatedï¼‰
            full_reply, llm_time, llm_first_sentence_time = llm_service.chat_stream(user_text, on_sentence_generated)
            
            logger.info(f"ğŸ’¬ LLM å®Œæ•´å›å¤: {full_reply}")
            logger.info(f"ğŸ§  LLM æ€»è€—æ—¶: {llm_time:.2f}s")
            logger.info(f"ğŸ—£ï¸ TTS æ€»åˆæˆè€—æ—¶: {tts_total_time:.2f}s (å…± {sentence_count} ä¸ªå¥å­)")
            
            pipeline_end_time = time.time()
            total_pipeline_time = pipeline_end_time - pipeline_start_time
            
            # è®¡ç®—å»¶è¿Ÿä¼˜åŒ–æ•ˆæœ
            logger.info("\n" + "~"*50)
            logger.info("--- è®¡æ—¶ç»“æœï¼ˆæµå¼ä¼˜åŒ–ï¼‰ ---")
            logger.info(f"ğŸ¤ ASR è€—æ—¶: {asr_time:.3f}s")
            logger.info(f"âš¡ é¦–å¥ç”Ÿæˆæ—¶é—´: {first_sentence_time if first_sentence_time else 0:.3f}s")
            logger.info(f"ğŸ’¡ é¦–æ¬¡å“åº”å»¶è¿Ÿ: {asr_time + (first_sentence_time if first_sentence_time else 0):.3f}s")
            logger.info(f"ğŸ§  LLM æ€»è€—æ—¶: {llm_time:.3f}s")
            logger.info(f"ğŸ—£ï¸ TTS æ€»è€—æ—¶: {tts_total_time:.3f}s")
            logger.info(f"ğŸ”¥ æ•´ä½“æ¨ç†æ€»ç”¨æ—¶: {total_pipeline_time:.3f}s")
            logger.info("~"*50)
            
            mem_pipeline_end = memory_monitor.get_memory_info()
            pipeline_delta = memory_monitor.get_memory_delta(mem_pipeline_start)
            logger.info(f"--- æœ¬è½®æ¨ç†å†…å­˜å˜åŒ–: {memory_monitor.format_delta(pipeline_delta)}")
            memory_monitor.log_memory("æœ¬è½®æ¨ç†å®Œæˆ")
            
            gc.collect()
            logger.info("--- æµç¨‹ç»“æŸ,è¿”å›å¾…å‘½çŠ¶æ€ ---\n")
            
        except KeyboardInterrupt:
            logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
            break
        except Exception as e:
            logger.error(f"âŒ æœªèƒ½è¯†åˆ«æœ‰æ•ˆè¯­éŸ³: {e}", exc_info=True)
            logger.info("âš ï¸ è·³è¿‡æœ¬è½®ï¼Œç»§ç»­ä¸‹ä¸€è½®...")
            gc.collect()
            continue

if __name__ == "__main__":
    main()
